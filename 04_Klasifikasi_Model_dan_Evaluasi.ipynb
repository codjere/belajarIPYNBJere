{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/codjere/belajarIPYNBJere/blob/main/04_Klasifikasi_Model_dan_Evaluasi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "!pip install wordcloud\n",
        "!pip install Sastrawi\n",
        "import nltk\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODquajyPsa5v",
        "outputId": "fda07c2b-218e-45b2-82c5-079db22b7391"
      },
      "id": "ODquajyPsa5v",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "005eccc4",
      "metadata": {
        "id": "005eccc4"
      },
      "source": [
        "# Pembacaan Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82e53b22",
      "metadata": {
        "id": "82e53b22"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ebff491",
      "metadata": {
        "id": "6ebff491"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"/content/Sentiment1.csv\", encoding='ISO-8859-1')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01b5ed77",
      "metadata": {
        "id": "01b5ed77"
      },
      "source": [
        "# DEA (Data Explorasi and Analisis)\n",
        "Tujuan: Pemahaman data (bentuk data, distribusi, missing values, data duplikat, distribusi label, dan kata-kata yang sering muncul).\n",
        "\n",
        "### Data Info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b11b9cd",
      "metadata": {
        "id": "0b11b9cd"
      },
      "outputs": [],
      "source": [
        "# cek bentuk data\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e2bcacd",
      "metadata": {
        "id": "3e2bcacd"
      },
      "outputs": [],
      "source": [
        "# melihat informasi didalam data\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e86b108",
      "metadata": {
        "id": "1e86b108"
      },
      "outputs": [],
      "source": [
        "data.drop(columns=['Date', 'Username', 'Length_Text'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55c5ca42",
      "metadata": {
        "id": "55c5ca42"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "833faa1a",
      "metadata": {
        "id": "833faa1a"
      },
      "outputs": [],
      "source": [
        "# melihat data deskripsi\n",
        "data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8edc9811",
      "metadata": {
        "id": "8edc9811"
      },
      "source": [
        "### Distribusi Label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77fb96af",
      "metadata": {
        "id": "77fb96af"
      },
      "outputs": [],
      "source": [
        "# Melihat distribusi persebaran label\n",
        "data.Sentiment.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb5f65bb",
      "metadata": {
        "id": "eb5f65bb"
      },
      "outputs": [],
      "source": [
        "print(f\"persentase data positif: {len(data[data['Sentiment'] == 'Positive'])/len(data)*100:.2f}%\")\n",
        "print(f\"persentase data negatif: {len(data[data['Sentiment'] == 'Negative'])/len(data)*100:.2f}%\")\n",
        "print(f\"persentase data netral: {len(data[data['Sentiment'] == 'Neutral'])/len(data)*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2556a59d",
      "metadata": {
        "id": "2556a59d"
      },
      "source": [
        "### Melihat data sampel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14a03a2b",
      "metadata": {
        "id": "14a03a2b"
      },
      "outputs": [],
      "source": [
        "# melihat data text pada index data ke 1\n",
        "data.Text[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35be0b1d",
      "metadata": {
        "id": "35be0b1d"
      },
      "source": [
        "### Data Missing dan Data Duplikat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab08f33e",
      "metadata": {
        "id": "ab08f33e"
      },
      "outputs": [],
      "source": [
        "# melihat missing value (data yang hilang) pada kolom komentar\n",
        "data.Text.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe09aba7",
      "metadata": {
        "id": "fe09aba7"
      },
      "outputs": [],
      "source": [
        "# Melihat baris duplikat\n",
        "duplicate_rows = data[data.duplicated()]\n",
        "print(\"Duplicate rows based on all columns:\\n\", duplicate_rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fac233a",
      "metadata": {
        "id": "7fac233a"
      },
      "outputs": [],
      "source": [
        "# menghitung total data duplikat\n",
        "data.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1674460",
      "metadata": {
        "id": "e1674460"
      },
      "outputs": [],
      "source": [
        "# Harus menghapus duplikasi\n",
        "data = data.drop_duplicates().reset_index(drop=True)\n",
        "# atau bisa juga menggunakan kode di bawah ini\n",
        "# data = data.drop_duplicates(keep='first')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c922e8a1",
      "metadata": {
        "id": "c922e8a1"
      },
      "outputs": [],
      "source": [
        "data.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed4bb191",
      "metadata": {
        "id": "ed4bb191"
      },
      "outputs": [],
      "source": [
        "data.Sentiment.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b61d5b55",
      "metadata": {
        "id": "b61d5b55"
      },
      "outputs": [],
      "source": [
        "988 - 979\n",
        "# ada pengurangan jumlah data positif sebanyak 9 data karena duplikasi"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5568e7ee",
      "metadata": {
        "id": "5568e7ee"
      },
      "source": [
        "### Sampling Technique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05f9c783",
      "metadata": {
        "id": "05f9c783"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "# buat data balancing technique dengan undersampling\n",
        "# Pisahkan berdasarkan kelas\n",
        "df_pos = data[data['Sentiment'] == \"Positive\"]\n",
        "df_neu = data[data['Sentiment'] == \"Neutral\"]\n",
        "df_neg = data[data['Sentiment'] == \"Negative\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c9b2b8a",
      "metadata": {
        "id": "4c9b2b8a"
      },
      "outputs": [],
      "source": [
        "print(f\"data positive : {df_pos.shape}\")\n",
        "print(f\"data neutral : {df_neu.shape}\")\n",
        "print(f\"data negative : {df_neg.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e314c186",
      "metadata": {
        "id": "e314c186"
      },
      "outputs": [],
      "source": [
        "# Tentukan target jumlah data (minoritas)\n",
        "min_count = min(len(df_neu), len(df_neg))  # = 161"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1bbf15e",
      "metadata": {
        "id": "d1bbf15e"
      },
      "outputs": [],
      "source": [
        "min_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ba3e564",
      "metadata": {
        "id": "4ba3e564"
      },
      "outputs": [],
      "source": [
        "# Downsampling kelas mayoritas (Positive â†’ 161)\n",
        "df_pos_down = resample(df_pos,\n",
        "                       replace=False,   # tidak melakukan duplikasi\n",
        "                       n_samples=min_count,\n",
        "                       random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2943c492",
      "metadata": {
        "id": "2943c492"
      },
      "outputs": [],
      "source": [
        "df_pos_down.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6197da63",
      "metadata": {
        "id": "6197da63"
      },
      "outputs": [],
      "source": [
        "# Gabungkan kembali dataset seimbang\n",
        "df_balanced = pd.concat([df_pos_down, df_neu, df_neg])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8a8d4aa",
      "metadata": {
        "id": "a8a8d4aa"
      },
      "outputs": [],
      "source": [
        "df_balanced.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e82a32dd",
      "metadata": {
        "id": "e82a32dd"
      },
      "outputs": [],
      "source": [
        "type(df_balanced)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "532ac469",
      "metadata": {
        "id": "532ac469"
      },
      "outputs": [],
      "source": [
        "df_balanced.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c40bd8ed",
      "metadata": {
        "id": "c40bd8ed"
      },
      "outputs": [],
      "source": [
        "# Shuffle hasil\n",
        "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0276ca04",
      "metadata": {
        "id": "0276ca04"
      },
      "outputs": [],
      "source": [
        "df_balanced.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "607abc3b",
      "metadata": {
        "id": "607abc3b"
      },
      "outputs": [],
      "source": [
        "print(df_balanced['Sentiment'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6ef7a96",
      "metadata": {
        "id": "c6ef7a96"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "501bbc12",
      "metadata": {
        "id": "501bbc12"
      },
      "outputs": [],
      "source": [
        "text = df_balanced.Text.iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa9eb575",
      "metadata": {
        "id": "fa9eb575"
      },
      "outputs": [],
      "source": [
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c019fb8a",
      "metadata": {
        "id": "c019fb8a"
      },
      "outputs": [],
      "source": [
        "# remove Lowercase\n",
        "text = text.lower()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b3fcf02",
      "metadata": {
        "id": "9b3fcf02"
      },
      "outputs": [],
      "source": [
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5473ac61",
      "metadata": {
        "id": "5473ac61"
      },
      "outputs": [],
      "source": [
        "# Menghapus tanda baca dan angka\n",
        "import re\n",
        "\n",
        "text = re.sub(r'[^a-zA-Z\\s]', '', text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcd5c239",
      "metadata": {
        "id": "fcd5c239"
      },
      "outputs": [],
      "source": [
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f41a1a0",
      "metadata": {
        "id": "0f41a1a0"
      },
      "outputs": [],
      "source": [
        "# menghapus Stopword\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words('indonesian'))\n",
        "tokens = [w for w in text.split() if w not in stop_words]\n",
        "text = \" \".join(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a51f648",
      "metadata": {
        "id": "2a51f648"
      },
      "outputs": [],
      "source": [
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "412cb8f0",
      "metadata": {
        "id": "412cb8f0"
      },
      "outputs": [],
      "source": [
        "# melakukan Tokenisasi\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "tokens = word_tokenize(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "133e7e37",
      "metadata": {
        "id": "133e7e37"
      },
      "outputs": [],
      "source": [
        "tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7a1e517",
      "metadata": {
        "id": "d7a1e517"
      },
      "outputs": [],
      "source": [
        "# melakukan stemming\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "\n",
        "stemmer = StemmerFactory().create_stemmer()\n",
        "text = stemmer.stem(text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66549cef",
      "metadata": {
        "id": "66549cef"
      },
      "outputs": [],
      "source": [
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d284d14c",
      "metadata": {
        "id": "d284d14c"
      },
      "outputs": [],
      "source": [
        "# melakukan lemmatization\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "tokens_lem = [lemmatizer.lemmatize(w) for w in tokens]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8066b86c",
      "metadata": {
        "id": "8066b86c"
      },
      "outputs": [],
      "source": [
        "tokens_lem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90db169f",
      "metadata": {
        "id": "90db169f"
      },
      "outputs": [],
      "source": [
        "# wrapping semua proses diatas\n",
        "def preprocess(text):\n",
        "    # 1. Lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # 2. Hapus angka & tanda baca\n",
        "    text = re.sub(r'http\\S+|@\\w+|#[A-Za-z0-9_]+|www\\.\\S+', '', text)   # hapus URL, mention, hashtag\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)                   # hapus angka & tanda baca\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()                  # rapikan spasi\n",
        "\n",
        "    # 3. Tokenisasi\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # 4. Stopword removal\n",
        "    tokens = [w for w in tokens if w not in stop_words]\n",
        "\n",
        "    # 5. Stemming\n",
        "    text = \" \".join(tokens)\n",
        "    text = stemmer.stem(text)\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3f51426",
      "metadata": {
        "id": "f3f51426"
      },
      "outputs": [],
      "source": [
        "df_balanced.Text = df_balanced.Text.apply(preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2b28fbc",
      "metadata": {
        "id": "b2b28fbc"
      },
      "outputs": [],
      "source": [
        "df_balanced.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0a00f1d",
      "metadata": {
        "id": "c0a00f1d"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def word_clod_plot(feature_name:str, data:pd.DataFrame):\n",
        "    \"\"\"_summary_\n",
        "\n",
        "    Args:\n",
        "        feature_name (str): _description_\n",
        "    \"\"\"\n",
        "    txt = data[data['Sentiment'] == feature_name]['Text']\n",
        "    wordcloud = WordCloud(width=800, height=400, background_color='white', stopwords=STOPWORDS).generate(' '.join(txt))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.title(f'Word Cloud for {feature_name} Text')\n",
        "    plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e00f2ce4",
      "metadata": {
        "id": "e00f2ce4"
      },
      "outputs": [],
      "source": [
        "word_clod_plot(feature_name='Positive', data=df_balanced)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3943ecc7",
      "metadata": {
        "id": "3943ecc7"
      },
      "outputs": [],
      "source": [
        "word_clod_plot(feature_name='Negative', data=df_balanced)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0484c0b4",
      "metadata": {
        "id": "0484c0b4"
      },
      "outputs": [],
      "source": [
        "word_clod_plot(feature_name='Neutral', data=df_balanced)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f274d15e",
      "metadata": {
        "id": "f274d15e"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "# tokenize the text\n",
        "def text_tokenize(text:str)->list:\n",
        "  return word_tokenize(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7ba3664",
      "metadata": {
        "id": "e7ba3664"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_df_balanced = TfidfVectorizer(analyzer=text_tokenize).fit_transform(df_balanced['Text'])\n",
        "# tfidf_transformer_X_test = TfidfVectorizer(analyzer=text_tokenize).fit_transform(df_balanced['Text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a0edb50",
      "metadata": {
        "id": "4a0edb50"
      },
      "outputs": [],
      "source": [
        "# type(tfidf_transformer_X_train)\n",
        "print(tfidf_df_balanced.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b39be2af",
      "metadata": {
        "id": "b39be2af"
      },
      "outputs": [],
      "source": [
        "tfidf_df_balanced.toarray().shape\n",
        "# 407 = jumlah dokumen (jumlah teks dalam dataset)\n",
        "# 2105 = jumlah fitur (jumlah kata unik setelah preprocessing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6ff3e94",
      "metadata": {
        "id": "a6ff3e94"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(tfidf_df_balanced.toarray())\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d93eb208",
      "metadata": {
        "id": "d93eb208"
      },
      "source": [
        "## Machine Learning Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c2512b2",
      "metadata": {
        "id": "8c2512b2"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4fb2c77",
      "metadata": {
        "id": "b4fb2c77"
      },
      "outputs": [],
      "source": [
        "df_balanced['Sentiment'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01273b12",
      "metadata": {
        "id": "01273b12"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = tfidf_df_balanced\n",
        "y = df_balanced['Sentiment']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fde6d0d4",
      "metadata": {
        "id": "fde6d0d4"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c950ef51",
      "metadata": {
        "id": "c950ef51"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "multiNB = MultinomialNB().fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0075e07",
      "metadata": {
        "id": "c0075e07"
      },
      "outputs": [],
      "source": [
        "multiNB.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bea848f5",
      "metadata": {
        "id": "bea848f5"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rfc = RandomForestClassifier(random_state=0).fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "feb17342",
      "metadata": {
        "id": "feb17342"
      },
      "outputs": [],
      "source": [
        "rfc.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ff2b3b9",
      "metadata": {
        "id": "6ff2b3b9"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8cc35af",
      "metadata": {
        "id": "c8cc35af"
      },
      "outputs": [],
      "source": [
        "y_pred = rfc.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9b340d3",
      "metadata": {
        "id": "c9b340d3"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print (classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab22dd74",
      "metadata": {
        "id": "ab22dd74"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "sns.heatmap(cm,\n",
        "            annot=True,\n",
        "            fmt='g',\n",
        "            xticklabels=['0','1','2'],\n",
        "            yticklabels=['0','1','2'])\n",
        "plt.ylabel('Actual', fontsize=13)\n",
        "plt.title('Confusion Matrix', fontsize=17, pad=20)\n",
        "plt.gca().xaxis.set_label_position('top')\n",
        "plt.xlabel('Prediction', fontsize=13)\n",
        "plt.gca().xaxis.tick_top()\n",
        "\n",
        "plt.gca().figure.subplots_adjust(bottom=0.2)\n",
        "plt.gca().figure.text(0.5, 0.05, 'Prediction', ha='center', fontsize=13)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "main",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}